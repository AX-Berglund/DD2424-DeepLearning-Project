data:
  task: 'semisupervised'
  task_type: 'multiclass'
  batch_size: 32  # Reduced from 64 to better fit M3 memory
  num_workers: 4  # Reduced from 8 to avoid overwhelming the system
  pin_memory: true
  image_size: 224
  data_dir: 'data/processed/semisupervised/multiclass'
  percentage_labeled: 50  # Can be 100, 50, 10, or 1
  train_val_test_split: [0.7, 0.15, 0.15]
  augmentation:
    use_augmentation: true

model:
  architecture: 'resnet18'
  pretrained: true
  num_classes: 10  # CIFAR-10 has 10 classes
  dropout_rate: 0.5

training:
  device: 'mps'  # Changed from 'cuda' to 'mps' for M3
  num_epochs: 12
  early_stopping_patience: 10
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: 'adam'
  scheduler: 'reduce_on_plateau'
  strategy: 'full'  # Options: 'full', 'last_layer', 'masked'
  unfreeze_layers: 1
  mixed_precision: false  # Disabled mixed precision as it's not supported on MPS
  fast_mode: false  # Enable this for faster training without detailed metrics during training

  # Learning rate scheduler
  lr_scheduler:
    use_scheduler: true
    type: "reduce_on_plateau"          # Options: step, cosine, reduce_on_plateau
    step_size: 5          # For StepLR
    gamma: 0.1            # Factor to reduce LR

  pseudo_labeling:
    confidence_threshold: 0.8
    rampup_epochs: 10
    warmup_epochs: 5
    alpha: 0.5  # Weight for pseudo-labeled loss

logging:
  experiment_name: "multiclass_pseudo_labeling"
  log_dir: "logs"
  tensorboard: true
  wandb: false
  log_interval: 20
  checkpoint_dir: "checkpoints"  # Added checkpoint directory configuration
  save_dir: 'checkpoints/multiclass_pseudo_labeling'
  save_interval: 5
  log_level: 'detailed'  # Options: 'debug', 'detailed', 'info', 'warning', 'error'
  metrics:
    - accuracy
    - f1_score
    - precision
    - recall 