# Configuration for semi-supervised learning with pseudo-labeling

# General settings
experiment_name: "pseudo_labeling"
seed: 42
device: "cuda"  # or "cpu"
num_workers: 4
task: "semisupervised"  # Specify task type as semisupervised

# Data settings
data:
  processed_path: "data/processed/semisupervised/50_percent_labeled"  # Point to specific percentage folder
  image_size: 224  # ResNet default input size
  batch_size: 32
  
  # Augmentation settings
  augmentation:
    use_augmentation: true
    horizontal_flip: true
    rotation_angle: 15
    random_crop: true
    color_jitter: true

# Model settings
model:
  architecture: "resnet18"  # Options: resnet18, resnet34, resnet50
  pretrained: true
  num_classes: 37  # Number of breeds

# Training settings
training:
  # Training strategy
  strategy: "multi_layer"  # Options: last_layer, multi_layer, gradual_unfreeze
  unfreeze_layers: 2       # Number of layers to unfreeze (for multi_layer)
  
  # Pseudo-labeling settings
  pseudo_labeling:
    confidence_threshold: 0.95  # Minimum confidence for pseudo-labels
    rampup_epochs: 5           # Number of epochs to ramp up pseudo-label weight
    alpha: 0.5                 # Maximum weight for pseudo-labeled loss
  
  # Multiple learning rates for different layer groups
  layer_specific_lr:
    enabled: true
    base_lr: 0.00001        # For pre-trained layers
    new_layers_lr: 0.001    # For newly added layers (increased for better class discrimination)
  
  # Optimization settings
  optimizer: "adamw"       # Options: adam, adamw, sgd
  learning_rate: 0.001     # Base learning rate (if layer_specific_lr is disabled)
  weight_decay: 0.01       # L2 regularization
  momentum: 0.9            # Only for SGD
  
  # Training schedule
  num_epochs: 30
  early_stopping_patience: 5
  
  # Learning rate scheduler
  lr_scheduler:
    use_scheduler: true
    type: "cosine"         # Options: step, cosine, reduce_on_plateau
    step_size: 10          # For StepLR
    gamma: 0.1             # Factor to reduce LR
    
  # Batch normalization updates
  update_batch_norm: true
  
  # Class imbalance handling
  class_imbalance:
    enabled: true          # Enable class imbalance handling
    strategy: "weighted_loss"  # Options: weighted_loss, oversampling, none
    imbalance_ratio: 0.2       # For creating artificially imbalanced dataset

# Logging settings
logging:
  log_interval: 10        # Log every N batches
  tensorboard: true
  wandb: true
  save_model: true
  checkpoint_dir: "models/pseudo_labeling"
  
# Evaluation settings
evaluation:
  evaluate_every: 1       # Evaluate on validation set every N epochs
  metrics: ["accuracy", "precision", "recall", "f1", "confusion_matrix", "per_class_accuracy"] 